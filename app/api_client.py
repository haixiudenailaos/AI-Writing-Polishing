from __future__ import annotations

import os
import sys
from typing import Any, Dict, Optional, List, TYPE_CHECKING

import requests
from app.config_manager import ConfigManager, APIConfig

# é¿å…å¾ªç¯å¯¼å…¥
if TYPE_CHECKING:
    from app.knowledge_base import KnowledgeBase, KnowledgeBaseManager, RerankClient


class AIError(RuntimeError):
    """è¡¨ç¤ºä¸ AI API äº¤äº’æ—¶å‘ç”Ÿçš„é”™è¯¯ã€‚"""


def truncate_context(text: str, max_chars: int = 1000) -> str:
    """æˆªå–ä¸Šä¸‹æ–‡æ–‡æœ¬ï¼Œæœ€å¤šä¿ç•™ max_chars ä¸ªå­—ç¬¦ï¼Œä¿æŒå¥å­å®Œæ•´æ€§
    
    Args:
        text: å®Œæ•´æ–‡æœ¬
        max_chars: æœ€å¤§å­—ç¬¦æ•°ï¼ˆé»˜è®¤1000å­—ï¼‰
        
    Returns:
        æˆªå–åçš„æ–‡æœ¬ï¼Œå¦‚æœåŸæ–‡ä¸è¶³ max_chars åˆ™è¿”å›å…¨éƒ¨
    """
    if not text:
        return ""
    
    # å¦‚æœæ–‡æœ¬é•¿åº¦ä¸è¶…è¿‡é™åˆ¶ï¼Œç›´æ¥è¿”å›å…¨éƒ¨
    if len(text) <= max_chars:
        return text
    
    # ä»åå¾€å‰æˆªå– max_chars ä¸ªå­—ç¬¦
    truncated = text[-max_chars:]
    
    # å®šä¹‰å¥å­ç»“æŸæ ‡è®°ï¼ˆä¸­æ–‡å’Œè‹±æ–‡ï¼‰
    sentence_endings = ['ã€‚', 'ï¼', 'ï¼Ÿ', 'â€¦', '.', '!', '?', '\n']
    
    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå®Œæ•´å¥å­çš„å¼€å§‹ä½ç½®ï¼ˆä»å‰å¾€åæ‰¾ç¬¬ä¸€ä¸ªå¥å­ç»“æŸæ ‡è®°ï¼‰
    first_sentence_end = -1
    for i, char in enumerate(truncated):
        if char in sentence_endings:
            first_sentence_end = i
            break
    
    # å¦‚æœæ‰¾åˆ°å¥å­ç»“æŸæ ‡è®°ï¼Œä»ä¸‹ä¸€ä¸ªå­—ç¬¦å¼€å§‹ï¼ˆä¿æŒå¥å­å®Œæ•´ï¼‰
    if first_sentence_end >= 0:
        # è·³è¿‡å¥å­ç»“æŸæ ‡è®°å’Œåç»­çš„ç©ºç™½å­—ç¬¦
        start_pos = first_sentence_end + 1
        while start_pos < len(truncated) and truncated[start_pos] in [' ', '\n', '\t', '\r']:
            start_pos += 1
        
        if start_pos < len(truncated):
            return truncated[start_pos:]
    
    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¥å­ç»“æŸæ ‡è®°ï¼Œè¿”å›åŸæˆªå–å†…å®¹
    return truncated


class AIClient:
    """AI æ¶¦è‰² API å®¢æˆ·ç«¯ã€‚"""

    _DEFAULT_BASE_URL = "https://api.siliconflow.cn/v1/chat/completions"

    def __init__(
        self,
        config_manager: Optional[ConfigManager] = None,
        api_key: Optional[str] = None,
        model: Optional[str] = None,
        base_url: Optional[str] = None,
        temperature: float = 0.2,
        timeout_seconds: int = 45,
    ) -> None:
        self._config_manager = config_manager
        
        # ä¼˜å…ˆä½¿ç”¨é…ç½®ç®¡ç†å™¨ä¸­çš„é…ç½®
        if self._config_manager:
            api_config = self._config_manager.get_api_config()
            self._api_key = api_key or api_config.api_key
            self._model = model or api_config.model
            self._base_url = base_url or api_config.base_url
        else:
            # å›é€€åˆ°ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼
            self._api_key = api_key or os.getenv("AI_API_KEY")
            self._model = model or os.getenv("AI_MODEL", "deepseek-ai/DeepSeek-V3.2-Exp")
            self._base_url = base_url or os.getenv("AI_BASE_URL", self._DEFAULT_BASE_URL)
        
        self._temperature = temperature
        self._timeout_seconds = timeout_seconds
        
        # æç®€é…ç½®ï¼šåªç”¨Sessionï¼Œè‡ªåŠ¨å¤„ç†è¿æ¥å¤ç”¨
        self._session = requests.Session()

    def _build_headers(self) -> Dict[str, str]:
        if not self._api_key:
            raise AIError("æœªé…ç½® AI API å¯†é’¥ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ AI_API_KEYã€‚")
        return {
            "Authorization": f"Bearer {self._api_key}",
            "Content-Type": "application/json",
        }
    
    def _print_token_usage(self, usage_data: Dict[str, Any], operation: str = "APIè°ƒç”¨"):
        """æ‰“å°Tokenä½¿ç”¨ç»Ÿè®¡
        
        Args:
            usage_data: APIè¿”å›çš„usageæ•°æ®
            operation: æ“ä½œæè¿°
        """
        if not usage_data:
            return
        
        input_tokens = usage_data.get('input_tokens', usage_data.get('prompt_tokens', 0))
        output_tokens = usage_data.get('output_tokens', usage_data.get('completion_tokens', 0))
        total_tokens = usage_data.get('total_tokens', input_tokens + output_tokens)
        
        # é˜¿é‡Œäº‘åƒé—®ä»·æ ¼å‚è€ƒï¼ˆå®é™…ä»·æ ¼å¯èƒ½å˜åŒ–ï¼Œè¯·æŸ¥é˜…å®˜ç½‘ï¼‰
        # qwen-plus: è¾“å…¥ 0.4å…ƒ/ç™¾ä¸‡tokens, è¾“å‡º 1.2å…ƒ/ç™¾ä¸‡tokens
        # qwen-max: è¾“å…¥ 4å…ƒ/ç™¾ä¸‡tokens, è¾“å‡º 12å…ƒ/ç™¾ä¸‡tokens
        # qwen-turbo: è¾“å…¥ 0.3å…ƒ/ç™¾ä¸‡tokens, è¾“å‡º 0.6å…ƒ/ç™¾ä¸‡tokens
        
        # æ ¹æ®æ¨¡å‹ä¼°ç®—æˆæœ¬ï¼ˆå‡è®¾ä½¿ç”¨qwen-plusï¼‰
        input_cost = (input_tokens / 1_000_000) * 0.4
        output_cost = (output_tokens / 1_000_000) * 1.2
        total_cost = input_cost + output_cost
        
        print("=" * 60)
        print(f"ğŸ“Š ã€Tokenæ¶ˆè€—ç»Ÿè®¡ - {operation}ã€‘")
        print(f"   è¾“å…¥tokens: {input_tokens:,}")
        print(f"   è¾“å‡ºtokens: {output_tokens:,}")
        print(f"   æ€»è®¡tokens: {total_tokens:,}")
        print(f"   é¢„ä¼°æˆæœ¬: Â¥{total_cost:.4f} (æŒ‰qwen-plusä»·æ ¼)")
        print(f"   è¾“å…¥æˆæœ¬: Â¥{input_cost:.6f}")
        print(f"   è¾“å‡ºæˆæœ¬: Â¥{output_cost:.6f}")
        print("=" * 60)

    def polish_text(self, text: str) -> str:
        payload = {
            "model": self._model,
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­æ–‡å°è¯´ç¼–è¾‘ï¼Œè¯·åœ¨ä¿ç•™åŸæ„çš„å‰æä¸‹æ¶¦è‰²ç”¨æˆ·æ–‡æœ¬ã€‚"
                        "ä¼˜åŒ–ç”¨è¯ã€å¥å¼ä¸èŠ‚å¥ï¼Œè¾“å‡ºæ¶¦è‰²åçš„å®Œæ•´æ–‡æœ¬ï¼Œä¸è¦åŒ…å«å¤šä½™è§£é‡Šã€‚"
                    ),
                },
                {"role": "user", "content": text},
            ],
            "temperature": self._temperature,
            "stream": False,
        }

        try:
            response = self._session.post(
                self._base_url,
                headers=self._build_headers(),
                json=payload,
                timeout=self._timeout_seconds,
            )
        except requests.RequestException as exc:
            raise AIError("ç½‘ç»œå¼‚å¸¸ï¼Œæ— æ³•è¿æ¥è‡³ AI æœåŠ¡ã€‚") from exc

        if response.status_code >= 500:
            raise AIError("AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")

        if response.status_code == 401:
            raise AIError("AI API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚")

        if not response.ok:
            raise AIError(f"æ¶¦è‰²å¤±è´¥ï¼š{response.status_code} {response.text}")

        try:
            data: Dict[str, Any] = response.json()
        except ValueError as exc:
            raise AIError("æ— æ³•è§£æ AI å“åº”ï¼Œè¯·ç¨åå†è¯•ã€‚") from exc

        choices = data.get("choices")
        if not choices:
            raise AIError("AI æœªè¿”å›å†…å®¹ï¼Œè¯·ç¨åå†è¯•ã€‚")

        message = choices[0].get("message", {})
        content = message.get("content")
        if not content:
            raise AIError("AI å“åº”å†…å®¹ä¸ºç©ºã€‚")
        
        # æ‰“å°Tokenä½¿ç”¨ç»Ÿè®¡
        if "usage" in data:
            self._print_token_usage(data["usage"], operation="æ¶¦è‰²")

        return content.strip()

    # æ–°å¢ï¼šä»…æ¶¦è‰²æœ€åä¸€è¡Œï¼Œå‘é€æœ€åäº”è¡Œä¸Šä¸‹æ–‡
    def polish_last_line(self, context_lines: List[str], target_line: str, style_prompt: str = "") -> str:
        import sys
        print(f"[DEBUG API] polish_last_line å¼€å§‹ï¼Œtarget_line={target_line[:30]}, contextè¡Œæ•°={len(context_lines)}", flush=True)
        sys.stdout.flush()
        
        context_text = "\n".join(context_lines) if context_lines else "(æ— )"
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯ - ä½¿ç”¨æ›´æ¸…æ™°çš„ç»“æ„
        system_content = "ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­æ–‡å°è¯´ç¼–è¾‘ã€‚"
        
        # å¦‚æœæœ‰é£æ ¼è¦æ±‚ï¼Œå°†å…¶ä½œä¸ºäººè®¾çš„ä¸€éƒ¨åˆ†
        if style_prompt:
            system_content += f"\n\nã€ä½ çš„æ¶¦è‰²é£æ ¼ã€‘\n{style_prompt}"
        
        # æ·»åŠ æ ¸å¿ƒä»»åŠ¡æŒ‡ä»¤
        system_content += (
            "\n\nã€æ ¸å¿ƒä»»åŠ¡ã€‘\n"
            "æ ¹æ®æä¾›çš„ä¸Šä¸‹æ–‡ï¼Œå¯¹æœ€åä¸€è¡Œæ–‡æœ¬è¿›è¡Œæ¶¦è‰²ã€‚\n"
            "\n"
            "ã€è¾“å‡ºè¦æ±‚ã€‘\n"
            "1. åªè¾“å‡ºæ¶¦è‰²åçš„é‚£ä¸€è¡Œæ–‡æœ¬ï¼Œä¸è¦è¾“å‡ºä¸Šä¸‹æ–‡\n"
            "2. ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€è¯´æ˜æˆ–æ ‡æ³¨\n"
            "3. ç›´æ¥è¾“å‡ºæ¶¦è‰²åçš„æ–‡æœ¬å†…å®¹å³å¯\n"
            "4. ä¿æŒåŸæ„å’Œæ ¸å¿ƒå†…å®¹ä¸å˜\n"
        )
        
        payload = {
            "model": self._model,
            "messages": [
                {
                    "role": "system",
                    "content": system_content,
                },
                {
                    "role": "user",
                    "content": f"ä¸Šä¸‹æ–‡ï¼š\n{context_text}\n\nå¾…æ¶¦è‰²æ–‡æœ¬ï¼š\n{target_line}\n\nè¯·è¾“å‡ºæ¶¦è‰²åçš„æ–‡æœ¬ï¼š",
                },
            ],
            "temperature": self._temperature,
            "stream": False,
        }

        print(f"[DEBUG API] å‡†å¤‡å‘é€è¯·æ±‚åˆ° {self._base_url}, model={self._model}", flush=True)
        sys.stdout.flush()
        
        try:
            response = self._session.post(
                self._base_url,
                headers=self._build_headers(),
                json=payload,
                timeout=self._timeout_seconds,
            )
            
            print(f"[DEBUG API] æ”¶åˆ°å“åº”ï¼ŒçŠ¶æ€ç : {response.status_code}", flush=True)
            sys.stdout.flush()
            
        except requests.RequestException as exc:
            print(f"[DEBUG API] è¯·æ±‚å¼‚å¸¸: {exc}", flush=True)
            sys.stdout.flush()
            raise AIError("ç½‘ç»œå¼‚å¸¸ï¼Œæ— æ³•è¿æ¥è‡³ AI æœåŠ¡ã€‚") from exc

        if response.status_code >= 500:
            print(f"[DEBUG API] æœåŠ¡å™¨é”™è¯¯: {response.status_code}", flush=True)
            sys.stdout.flush()
            raise AIError("AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")

        if response.status_code == 401:
            print(f"[DEBUG API] è®¤è¯å¤±è´¥", flush=True)
            sys.stdout.flush()
            raise AIError("AI API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚")

        if not response.ok:
            print(f"[DEBUG API] å“åº”é”™è¯¯: {response.status_code} {response.text[:100]}", flush=True)
            sys.stdout.flush()
            raise AIError(f"æ¶¦è‰²å¤±è´¥ï¼š{response.status_code} {response.text}")

        try:
            data: Dict[str, Any] = response.json()
            print(f"[DEBUG API] è§£æJSONæˆåŠŸ", flush=True)
            sys.stdout.flush()
        except ValueError as exc:
            print(f"[DEBUG API] JSONè§£æå¤±è´¥", flush=True)
            sys.stdout.flush()
            raise AIError("æ— æ³•è§£æ AI å“åº”ï¼Œè¯·ç¨åå†è¯•ã€‚") from exc

        choices = data.get("choices")
        if not choices:
            print(f"[DEBUG API] æ²¡æœ‰choices", flush=True)
            sys.stdout.flush()
            raise AIError("AI æœªè¿”å›å†…å®¹ï¼Œè¯·ç¨åå†è¯•ã€‚")

        message = choices[0].get("message", {})
        content = message.get("content")
        if not content:
            print(f"[DEBUG API] contentä¸ºç©º", flush=True)
            sys.stdout.flush()
            raise AIError("AI å“åº”å†…å®¹ä¸ºç©ºã€‚")

        print(f"[DEBUG API] polish_last_line å®Œæˆï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content)}", flush=True)
        print(f"[DEBUG API] contentåŸå§‹å†…å®¹: {repr(content)}", flush=True)
        sys.stdout.flush()
        
        # æ‰“å°Tokenä½¿ç”¨ç»Ÿè®¡
        if "usage" in data:
            self._print_token_usage(data["usage"], operation="æ¶¦è‰²æœ€åä¸€è¡Œ")
        
        result = content.strip()
        print(f"[DEBUG API] stripåå†…å®¹: {repr(result)}", flush=True)
        print(f"[DEBUG API] å‡†å¤‡è¿”å›ï¼Œé•¿åº¦: {len(result)}", flush=True)
        sys.stdout.flush()
        
        return result

    def optimize_prompt(self, prompt_text: str) -> str:
        if not prompt_text or not prompt_text.strip():
            raise AIError("æç¤ºè¯ä¸ºç©ºï¼Œæ— æ³•ä¼˜åŒ–ã€‚")
        payload = {
            "model": self._model,
            "messages": [
                {
                    "role": "system",
                    "content": (
                        "ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­æ–‡æç¤ºè¯å·¥ç¨‹å¸ˆã€‚" \
                        "è¯·å°†ç”¨æˆ·æä¾›çš„æ¶¦è‰²é£æ ¼æç¤ºè¯è¿›è¡Œç»“æ„åŒ–ä¸å¢å¼ºï¼š" \
                        "æ˜ç¡®ç›®æ ‡ã€é£æ ¼è¦ç‚¹ã€çº¦æŸã€è¾“å‡ºè¦æ±‚ï¼›é¿å…å†—ä½™ä¸å«ç³Šï¼›" \
                        "ä¿æŒä¸­æ–‡è¾“å‡ºï¼Œåªè¿”å›ä¼˜åŒ–åçš„æç¤ºè¯æœ¬èº«ï¼Œä¸è¦è§£é‡Šã€‚"
                    ),
                },
                {"role": "user", "content": prompt_text},
            ],
            "temperature": self._temperature,
            "stream": False,
        }
        try:
            response = self._session.post(
                self._base_url,
                headers=self._build_headers(),
                json=payload,
                timeout=self._timeout_seconds,
            )
        except requests.RequestException as exc:
            raise AIError("ç½‘ç»œå¼‚å¸¸ï¼Œæ— æ³•è¿æ¥è‡³ AI æœåŠ¡ã€‚") from exc
        if response.status_code >= 500:
            raise AIError("AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        if response.status_code == 401:
            raise AIError("AI API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚")
        if not response.ok:
            raise AIError(f"æç¤ºè¯ä¼˜åŒ–å¤±è´¥ï¼š{response.status_code} {response.text}")
        try:
            data: Dict[str, Any] = response.json()
        except ValueError as exc:
            raise AIError("æ— æ³•è§£æ AI å“åº”ï¼Œè¯·ç¨åå†è¯•ã€‚") from exc
        
        # æ‰“å°Tokenä½¿ç”¨ç»Ÿè®¡
        if "usage" in data:
            self._print_token_usage(data["usage"], operation="ä¼˜åŒ–æç¤ºè¯")
        
        choices = data.get("choices")
        if not choices:
            raise AIError("AI æœªè¿”å›å†…å®¹ï¼Œè¯·ç¨åå†è¯•ã€‚")
        message = choices[0].get("message", {})
        content = message.get("content")
        if not content:
            raise AIError("AI å“åº”å†…å®¹ä¸ºç©ºã€‚")
        return content.strip()

    def update_config(self, config_manager: ConfigManager) -> None:
        """æ›´æ–°é…ç½®ç®¡ç†å™¨"""
        self._config_manager = config_manager
        if self._config_manager:
            api_config = self._config_manager.get_api_config()
            self._api_key = api_config.api_key
            self._model = api_config.model
            self._base_url = api_config.base_url
    
    def predict_plot_continuation(self, full_text: str, style_prompt: str = "") -> str:
        """é¢„æµ‹å‰§æƒ…å‘å±•ï¼Œç”Ÿæˆæ¥ä¸‹æ¥ä¸¤è¡Œå†…å®¹
        
        Args:
            full_text: å½“å‰ç¼–è¾‘å™¨ä¸­çš„å…¨éƒ¨æ–‡æœ¬å†…å®¹
            style_prompt: é£æ ¼æç¤ºè¯ï¼ˆå¯é€‰ï¼‰ï¼Œå°†ä½œä¸ºäººè®¾å‘é€ç»™AI
            
        Returns:
            é¢„æµ‹çš„æ¥ä¸‹æ¥ä¸¤è¡Œå‰§æƒ…å†…å®¹
        """
        if not full_text or not full_text.strip():
            raise AIError("æ–‡æœ¬å†…å®¹ä¸ºç©ºï¼Œæ— æ³•é¢„æµ‹å‰§æƒ…ã€‚")
        
        # æˆªå–ä¸Šä¸‹æ–‡ï¼šæœ€å¤š1000å­—ï¼Œä¿æŒå¥å­å®Œæ•´
        context_text = truncate_context(full_text, max_chars=1000)
        
        # æ„å»ºåŸºç¡€ç³»ç»Ÿæç¤ºè¯
        system_content = (
            "ä½ æ˜¯ä¸€ä½å¯Œæœ‰åˆ›é€ åŠ›çš„èµ„æ·±ä¸­æ–‡å°è¯´ä½œå®¶ï¼Œæ“…é•¿ä¸ºåˆ›ä½œè€…æä¾›æ–°é¢–çš„å‰§æƒ…æ€è·¯ã€‚\n"
            "ä½ çš„æ ¸å¿ƒä»·å€¼ï¼šä¸æ˜¯æœºæ¢°ç»­å†™ï¼Œè€Œæ˜¯æ¿€å‘åˆ›ä½œè€…çš„çµæ„Ÿï¼Œæä¾›ã€Œæ„æ–™ä¹‹å¤–ã€æƒ…ç†ä¹‹ä¸­ã€çš„ç²¾å½©å‘å±•ã€‚"
        )
        
        # å¦‚æœæœ‰é£æ ¼æç¤ºè¯ï¼Œå°†å…¶ä½œä¸ºäººè®¾çš„ä¸€éƒ¨åˆ†
        if style_prompt:
            system_content += f"\n\n{style_prompt}"
        
        # æ·»åŠ ä»»åŠ¡è¦æ±‚
        system_content += (
            "\n\nã€æ‰§è¡Œè¦æ±‚ã€‘\n"
            "1ï¼‰æ·±åº¦åˆ†æï¼šç†è§£å½“å‰æƒ…å¢ƒçš„æ½œåœ¨å†²çªã€äººç‰©åŠ¨æœºã€éšè—çº¿ç´¢\n"
            "2ï¼‰åˆ›æ„ä¼˜å…ˆï¼šä¼˜å…ˆè€ƒè™‘æœ‰æˆå‰§å¼ åŠ›ã€æƒ…æ„Ÿå†²å‡»çš„å‘å±•æ–¹å‘\n"
            "3ï¼‰åˆç†åˆ›æ–°ï¼šç¡®ä¿åˆ›æ„å»ºç«‹åœ¨å·²æœ‰ä¿¡æ¯çš„é€»è¾‘åŸºç¡€ä¸Š\n"
            "4ï¼‰é£æ ¼å¥‘åˆï¼šç”¨ç¬¦åˆä½œå“é£æ ¼çš„è¯­è¨€è¡¨è¾¾åˆ›æ„\n"
            "5ï¼‰ç²¾ç‚¼è¾“å‡ºï¼šåªè¾“å‡ºä¸¤è¡Œçº¯æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€ä¸ªå®Œæ•´å¥å­ï¼‰ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€æ ‡æ³¨æˆ–å…ƒæ•°æ®\n"
            "6ï¼‰æ— ç¼è¡”æ¥ï¼šç¡®ä¿è¾“å‡ºå¯ä»¥ç›´æ¥æ¥ç»­å½“å‰æ–‡æœ¬æœ«å°¾"
        )
        
        payload = {
            "model": self._model,
            "messages": [
                {
                    "role": "system",
                    "content": system_content,
                },
                {
                    "role": "user",
                    "content": f"ã€å½“å‰å‰§æƒ…ã€‘\n{context_text}\n\nè¯·åŸºäºä¸Šè¿°å‰§æƒ…ï¼Œç”Ÿæˆä»¤äººçœ¼å‰ä¸€äº®çš„åç»­ä¸¤è¡Œå†…å®¹ï¼ˆç›´æ¥è¾“å‡ºä¸¤è¡Œæ–‡æœ¬ï¼‰ï¼š"
                },
            ],
            "temperature": 0.85,  # ä½¿ç”¨è¾ƒé«˜æ¸©åº¦ä»¥å¢åŠ åˆ›é€ æ€§å’Œæ„å¤–æ€§
            "stream": False,
        }
        
        try:
            response = self._session.post(
                self._base_url,
                headers=self._build_headers(),
                json=payload,
                timeout=self._timeout_seconds,
            )
        except requests.RequestException as exc:
            raise AIError("ç½‘ç»œå¼‚å¸¸ï¼Œæ— æ³•è¿æ¥è‡³ AI æœåŠ¡ã€‚") from exc
        
        if response.status_code >= 500:
            raise AIError("AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        
        if response.status_code == 401:
            raise AIError("AI API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚")
        
        if not response.ok:
            raise AIError(f"å‰§æƒ…é¢„æµ‹å¤±è´¥ï¼š{response.status_code} {response.text}")
        
        try:
            data: Dict[str, Any] = response.json()
        except ValueError as exc:
            raise AIError("æ— æ³•è§£æ AI å“åº”ï¼Œè¯·ç¨åå†è¯•ã€‚") from exc
        
        # æ‰“å°Tokenä½¿ç”¨ç»Ÿè®¡
        if "usage" in data:
            self._print_token_usage(data["usage"], operation="_call_apié€šç”¨è°ƒç”¨")
        
        choices = data.get("choices")
        if not choices:
            raise AIError("AI æœªè¿”å›å†…å®¹ï¼Œè¯·ç¨åå†è¯•ã€‚")
        
        message = choices[0].get("message", {})
        content = message.get("content")
        if not content:
            raise AIError("AI å“åº”å†…å®¹ä¸ºç©ºã€‚")
        
        return content.strip()
    
    def _enhance_query_with_context(self, query_text: str) -> str:
        """æŸ¥è¯¢æ‰©å±•ï¼šæå–å…³é”®ä¿¡æ¯å¢å¼ºæŸ¥è¯¢
        
        Args:
            query_text: åŸå§‹æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            å¢å¼ºåçš„æŸ¥è¯¢æ–‡æœ¬
        """
        # ç®€å•çš„å…³é”®è¯æå–ç­–ç•¥
        # æå–å¯èƒ½çš„äººåã€åœºæ™¯ã€æƒ…èŠ‚å…³é”®è¯
        enhanced_query = query_text
        
        # æå–å¼•å·å†…çš„å¯¹è¯å’Œä¸“æœ‰åè¯ï¼ˆé€šå¸¸æ˜¯å…³é”®ä¿¡æ¯ï¼‰
        import re
        quoted_text = re.findall(r'[ã€Œã€"\'](.*?)[ã€ã€"\']', query_text)
        if quoted_text:
            # å°†å¯¹è¯å†…å®¹æƒé‡æå‡
            enhanced_query = query_text + "\nå…³é”®å¯¹è¯: " + " ".join(quoted_text)
        
        # æå–å¯èƒ½çš„äººåï¼ˆä¸­æ–‡å§“åæ¨¡å¼ï¼š2-4ä¸ªæ±‰å­—ï¼‰
        # åŒ¹é…å¸¸è§å§“æ°å¼€å¤´çš„2-4å­—äººå
        names = re.findall(r'[èµµé’±å­™æå‘¨å´éƒ‘ç‹å†¯é™ˆè¤šå«è’‹æ²ˆéŸ©æ¨æœ±ç§¦å°¤è®¸ä½•å•æ–½å¼ å­”æ›¹ä¸¥åé‡‘é­é™¶å§œ][ä¸€-é¾¥]{1,3}(?=[ï¼Œã€‚ï¼ï¼Ÿ\s"ã€ã€]|$)', query_text)
        if names:
            enhanced_query += "\nç›¸å…³äººç‰©: " + " ".join(set(names))
        
        return enhanced_query
    
    def predict_plot_continuation_with_kb(
        self,
        current_context: str,
        kb_manager: 'KnowledgeBaseManager',
        kb: 'KnowledgeBase',
        rerank_client: Optional['RerankClient'] = None,
        style_prompt: str = "",
        min_relevance_threshold: float = 0.25
    ) -> str:
        """åŸºäºçŸ¥è¯†åº“çš„å¢å¼ºå‰§æƒ…é¢„æµ‹ï¼ˆå¸¦æŸ¥è¯¢æ‰©å±•ï¼‰
        
        Args:
            current_context: å½“å‰ç¼–è¾‘ä½ç½®çš„ä¸Šä¸‹æ–‡ï¼ˆä¸Šæ–¹ä¸¤è¡Œï¼‰
            kb_manager: çŸ¥è¯†åº“ç®¡ç†å™¨
            kb: çŸ¥è¯†åº“å¯¹è±¡
            rerank_client: é‡æ’åºå®¢æˆ·ç«¯ï¼ˆå¯é€‰ï¼‰
            style_prompt: é£æ ¼æç¤ºè¯
            min_relevance_threshold: æœ€å°ç›¸å…³æ€§é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„ç»“æœä¼šè¢«è¿‡æ»¤ï¼ˆé»˜è®¤0.25ï¼‰
            
        Returns:
            é¢„æµ‹çš„å‰§æƒ…å†…å®¹
        """
        # 1. å¦‚æœçŸ¥è¯†åº“ä¸ºç©ºï¼Œå›é€€åˆ°æ™®é€šé¢„æµ‹
        if not kb or not kb.documents:
            print("[INFO] çŸ¥è¯†åº“ä¸ºç©ºï¼Œä½¿ç”¨æ™®é€šé¢„æµ‹")
            return self.predict_plot_continuation(current_context, style_prompt)
        
        # 2. ä½¿ç”¨æŸ¥è¯¢æ‰©å±•å¢å¼ºæ£€ç´¢æ•ˆæœ
        try:
            print(f"[INFO] å¼€å§‹çŸ¥è¯†åº“æ£€ç´¢ï¼ŒçŸ¥è¯†åº“æ–‡æ¡£æ•°: {len(kb.documents)}")
            print(f"[INFO] é‡æ’å®¢æˆ·ç«¯çŠ¶æ€: {'å·²æä¾›' if rerank_client else 'æœªæä¾›'}")
            if rerank_client:
                print(f"[INFO] é‡æ’å®¢æˆ·ç«¯å¯¹è±¡: {rerank_client}")
            
            # æŸ¥è¯¢æ‰©å±•ï¼šæå–å…³é”®ä¿¡æ¯å¢å¼ºæŸ¥è¯¢
            enhanced_query = self._enhance_query_with_context(current_context)
            if enhanced_query != current_context:
                print(f"[INFO] æŸ¥è¯¢æ‰©å±•å·²å¯ç”¨ï¼ŒåŸå§‹æŸ¥è¯¢é•¿åº¦: {len(current_context)}, å¢å¼ºå: {len(enhanced_query)}")
            
            # æœç´¢ç›¸ä¼¼æ–‡æ¡£ï¼ˆä½¿ç”¨å¢å¼ºæŸ¥è¯¢å’Œæ›´å¤§çš„å€™é€‰é›†ï¼‰
            similar_docs = kb_manager.search_similar_documents(
                query_text=enhanced_query,  # ä½¿ç”¨å¢å¼ºåçš„æŸ¥è¯¢
                kb=kb,
                top_k=25,  # å‘é‡æ£€ç´¢å…ˆå–25ä¸ªå€™é€‰ï¼ˆå·²ä¼˜åŒ–ï¼šå¢åŠ å¬å›ç‡ï¼‰
                rerank_client=rerank_client,
                final_top_n=5  # é‡æ’åå–æœ€å¤š5ä¸ªæœ€ç›¸å…³çš„
            )
            
            # 3. æ ¹æ®åŠ¨æ€é˜ˆå€¼è¿‡æ»¤ä½è´¨é‡ç»“æœï¼ˆä¼˜åŒ–ç‰ˆï¼‰
            filtered_docs = []
            
            if similar_docs:
                # åŠ¨æ€é˜ˆå€¼ç­–ç•¥ï¼šåŸºäºæœ€é«˜åˆ†æ•°è°ƒæ•´é˜ˆå€¼
                max_score = similar_docs[0].get('relevance_score', similar_docs[0].get('similarity_score', 0))
                
                # å¦‚æœæœ€é«˜åˆ†æ•°å¾ˆé«˜(>=0.7)ï¼Œä½¿ç”¨ç›¸å¯¹é˜ˆå€¼ï¼ˆæœ€é«˜åˆ†çš„40%ï¼‰
                # å¦‚æœæœ€é«˜åˆ†æ•°ä¸­ç­‰(0.4-0.7)ï¼Œä½¿ç”¨è¾ƒä½çš„ç›¸å¯¹é˜ˆå€¼ï¼ˆæœ€é«˜åˆ†çš„30%ï¼‰
                # å¦‚æœæœ€é«˜åˆ†æ•°è¾ƒä½(<0.4)ï¼Œä½¿ç”¨ç»å¯¹æœ€ä½é˜ˆå€¼
                if max_score >= 0.7:
                    dynamic_threshold = max(min_relevance_threshold, max_score * 0.4)
                elif max_score >= 0.4:
                    dynamic_threshold = max(min_relevance_threshold, max_score * 0.3)
                else:
                    dynamic_threshold = min_relevance_threshold
                
                print(f"[INFO] åŠ¨æ€é˜ˆå€¼è®¡ç®—ï¼šæœ€é«˜åˆ†={max_score:.3f}ï¼ŒåŠ¨æ€é˜ˆå€¼={dynamic_threshold:.3f}ï¼ŒåŸºç¡€é˜ˆå€¼={min_relevance_threshold:.3f}")
                
                for doc_item in similar_docs:
                    # å¦‚æœæœ‰é‡æ’åˆ†æ•°ï¼Œä½¿ç”¨é‡æ’åˆ†æ•°ï¼›å¦åˆ™ä½¿ç”¨ç›¸ä¼¼åº¦åˆ†æ•°
                    score = doc_item.get('relevance_score', doc_item.get('similarity_score', 0))
                    
                    if score >= dynamic_threshold:
                        filtered_docs.append(doc_item)
                
                # å¦‚æœè¿‡æ»¤åæ²¡æœ‰ç»“æœï¼Œè‡³å°‘ä¿ç•™ç›¸å…³æ€§æœ€é«˜çš„1-2ä¸ªæ–‡æ¡£
                if not filtered_docs:
                    filtered_docs = similar_docs[:min(2, len(similar_docs))]
                    print(f"[INFO] çŸ¥è¯†åº“æ£€ç´¢ï¼šæ‰€æœ‰æ–‡æ¡£ç›¸å…³æ€§ä½äºé˜ˆå€¼ï¼Œä¿ç•™æœ€é«˜çš„ {len(filtered_docs)} ä¸ª")
                
                # é™åˆ¶æœ€å¤šè¿”å›5ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£ï¼ˆé¿å…ä¸Šä¸‹æ–‡è¿‡é•¿ï¼‰
                filtered_docs = filtered_docs[:5]
            
            print(f"[INFO] çŸ¥è¯†åº“æ£€ç´¢ï¼šæ‰¾åˆ° {len(similar_docs)} ä¸ªç›¸ä¼¼æ–‡æ¡£ï¼Œè¿‡æ»¤åä¿ç•™ {len(filtered_docs)} ä¸ª")
            
            # 4. å¦‚æœç¡®å®æ²¡æœ‰ç»“æœï¼ˆçŸ¥è¯†åº“ä¸ºç©ºï¼‰ï¼Œå›é€€åˆ°æ™®é€šé¢„æµ‹
            if not filtered_docs:
                print("[INFO] æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹ï¼Œä½¿ç”¨æ™®é€šé¢„æµ‹")
                return self.predict_plot_continuation(current_context, style_prompt)
            
            # 5. æå–æ¯ä¸ªæ–‡æ¡£çš„ä¸Šä¸‹æ–‡
            kb_contexts = []
            for doc_item in filtered_docs:
                doc = doc_item['document']
                
                # è·å–æ–‡æ¡£åŠå…¶ä¸Šä¸‹æ–‡ï¼ˆä½¿ç”¨æ›´å¤§çš„ä¸Šä¸‹æ–‡çª—å£ä»¥æä¾›æ›´å®Œæ•´çš„ä¿¡æ¯ï¼‰
                doc_with_context = kb_manager.get_document_with_context(
                    doc=doc,
                    kb=kb,
                    context_lines_before=4,
                    context_lines_after=4
                )
                
                kb_contexts.append({
                    'content': doc.content,
                    'full_context': doc_with_context['full_context'],
                    'file_path': doc_with_context['file_path'],
                    'score': doc_item.get('relevance_score', doc_item.get('similarity_score', 0))
                })
            
            # 6. æ„å»ºå¢å¼ºçš„é¢„æµ‹promptï¼ˆåˆ›æ„å¯¼å‘ä¼˜åŒ–ç‰ˆï¼‰
            # æ„å»ºç³»ç»Ÿæç¤ºè¯
            system_content = (
                "ä½ æ˜¯ä¸€ä½å¯Œæœ‰åˆ›é€ åŠ›çš„èµ„æ·±ä¸­æ–‡å°è¯´ä½œå®¶ï¼Œæ“…é•¿ä¸ºåˆ›ä½œè€…æä¾›æ–°é¢–çš„å‰§æƒ…æ€è·¯ã€‚\n"
                "ä½ å°†åŸºäºå½“å‰ä¸Šä¸‹æ–‡å’ŒçŸ¥è¯†åº“å‚è€ƒï¼Œç”Ÿæˆã€Œæ„æ–™ä¹‹å¤–ã€æƒ…ç†ä¹‹ä¸­ã€çš„ç²¾å½©åç»­å‰§æƒ…ã€‚\n\n"
                "ã€å¦‚ä½•åˆ›é€ æ€§ä½¿ç”¨çŸ¥è¯†åº“å‚è€ƒã€‘\n"
                "âœ¦ å‚è€ƒå†…å®¹çš„ä»·å€¼ï¼š\n"
                "  â€¢ æ­ç¤ºä½œå“çš„äººç‰©æ€§æ ¼æ·±å±‚é€»è¾‘ã€æƒ…èŠ‚è½¬æŠ˜è§„å¾‹ã€æ½œåœ¨ä¼ç¬”\n"
                "  â€¢ å±•ç°ä½œè€…åå¥½çš„å™äº‹æŠ€å·§ã€æˆå‰§å†²çªæ¨¡å¼ã€æƒ…æ„Ÿè¡¨è¾¾æ–¹å¼\n"
                "  â€¢ æä¾›å¯å€Ÿé‰´çš„åˆ›æ„å…ƒç´ ã€æ„å¤–è½¬æŠ˜ã€äººç‰©å…³ç³»å¼ åŠ›\n"
                "âœ¦ åˆ›æ„è¿ç”¨ç­–ç•¥ï¼š\n"
                "  1. ä»å‚è€ƒä¸­è¯†åˆ«ã€Œæ„å¤–ä½†åˆç†ã€çš„æƒ…èŠ‚æ¨¡å¼ï¼Œè¿ç§»åˆ°å½“å‰æƒ…å¢ƒ\n"
                "  2. å‘ç°å‚è€ƒä¸­éšè—çš„ä¼ç¬”çº¿ç´¢ï¼Œåœ¨åç»­å‰§æƒ…ä¸­å·§å¦™å‘¼åº”\n"
                "  3. å­¦ä¹ å‚è€ƒä¸­åˆ¶é€ æ‚¬å¿µã€åè½¬ã€å†²çªçš„æŠ€å·§\n"
                "  4. æŠŠæ¡å‚è€ƒä¸­äººç‰©çš„æ ¸å¿ƒåŠ¨æœºå’Œè¡Œä¸ºé€»è¾‘\n"
                "  5. ç›¸å…³åº¦è¶Šé«˜çš„å‚è€ƒï¼Œè¶Šèƒ½æä¾›ç²¾å‡†çš„åˆ›æ„çµæ„Ÿ\n"
                "âœ¦ æ³¨æ„äº‹é¡¹ï¼š\n"
                "  Ã— ä¸è¦æœºæ¢°å¤åˆ¶å‚è€ƒå†…å®¹ï¼Œè¦åˆ›é€ æ€§è½¬åŒ–\n"
                "  Ã— å¦‚æœå‚è€ƒä¸å½“å‰å†²çªï¼Œä»¥å½“å‰ä¸Šä¸‹æ–‡ä¸ºå‡†\n"
                "  Ã— é¿å…å¹³åº¸ç»­å†™ï¼Œè¦æœ‰åˆ›æ–°æ€ç»´"
            )
            
            # æ·»åŠ é£æ ¼è¦æ±‚
            if style_prompt:
                system_content += f"\n\n{style_prompt}"
            
            # æ·»åŠ ä»»åŠ¡è¦æ±‚
            system_content += (
                "\n\nã€æ‰§è¡Œè¦æ±‚ã€‘\n"
                "1. æ·±åº¦åˆ†æï¼šç»¼åˆå½“å‰å‰§æƒ…å’ŒçŸ¥è¯†åº“å‚è€ƒï¼ŒæŒ–æ˜æ½œåœ¨å†²çªç‚¹å’Œè½¬æŠ˜å¯èƒ½\n"
                "2. åˆ›æ„ä¼˜å…ˆï¼šä»å¤šä¸ªå¯èƒ½æ–¹å‘ä¸­ï¼Œé€‰æ‹©æœ€æœ‰æˆå‰§å¼ åŠ›å’Œæƒ…æ„Ÿå†²å‡»çš„ä¸€ä¸ª\n"
                "3. åˆç†åˆ›æ–°ï¼šç¡®ä¿åˆ›æ„æ—¢æ–°é¢–åˆç¬¦åˆä½œå“å·²å»ºç«‹çš„é€»è¾‘å’Œäººç‰©è®¾å®š\n"
                "4. é£æ ¼å¥‘åˆï¼šç”¨ä¸å‚è€ƒå†…å®¹ä¸€è‡´çš„è¯­è¨€é£æ ¼è¡¨è¾¾åˆ›æ„\n"
                "5. ç²¾ç‚¼è¾“å‡ºï¼šåªè¾“å‡ºä¸¤è¡Œçº¯æ–‡æœ¬ï¼ˆæ¯è¡Œä¸€ä¸ªå®Œæ•´å¥å­ï¼‰ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€æ ‡æ³¨æˆ–å…ƒæ•°æ®\n"
                "6. æ— ç¼è¡”æ¥ï¼šç¡®ä¿è¾“å‡ºå¯ä»¥ç›´æ¥æ¥ç»­å½“å‰æ–‡æœ¬æœ«å°¾"
            )
            
            # æ„å»ºç”¨æˆ·æç¤ºè¯ï¼ˆç»“æ„åŒ–å‘ˆç°ï¼‰
            user_content = "ã€å½“å‰ä¸Šä¸‹æ–‡ã€‘\n" + current_context + "\n\n"
            
            # æ·»åŠ çŸ¥è¯†åº“å‚è€ƒå†…å®¹ï¼ˆå¸¦ç›¸å…³åº¦æ ‡æ³¨ï¼‰
            user_content += "ã€çŸ¥è¯†åº“ç›¸å…³å‚è€ƒã€‘\n"
            user_content += f"ï¼ˆå…±æ‰¾åˆ° {len(kb_contexts)} ä¸ªç›¸å…³ç‰‡æ®µï¼ŒæŒ‰ç›¸å…³åº¦æ’åºï¼‰\n\n"
            
            for i, ctx in enumerate(kb_contexts, 1):
                score = ctx['score']
                # æ ¹æ®åˆ†æ•°æ·»åŠ ç›¸å…³æ€§æ ‡ç­¾
                if score >= 0.7:
                    relevance_label = "é«˜åº¦ç›¸å…³"
                elif score >= 0.5:
                    relevance_label = "è¾ƒä¸ºç›¸å…³"
                elif score >= 0.3:
                    relevance_label = "ä¸­ç­‰ç›¸å…³"
                else:
                    relevance_label = "å¼±ç›¸å…³"
                
                user_content += f"â•â•â• å‚è€ƒç‰‡æ®µ {i} â•â•â•\n"
                user_content += f"ç›¸å…³åº¦: {score:.3f} ({relevance_label})\n"
                user_content += f"å†…å®¹:\n{ctx['full_context']}\n\n"
            
            user_content += "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n"
            user_content += "ç°åœ¨ï¼Œè¯·æ·±åº¦åˆ†æã€å½“å‰ä¸Šä¸‹æ–‡ã€‘çš„æ½œåœ¨èµ°å‘ï¼Œä»ã€çŸ¥è¯†åº“ç›¸å…³å‚è€ƒã€‘ä¸­æ±²å–åˆ›æ„çµæ„Ÿï¼Œ\n"
            user_content += "ç”Ÿæˆä»¤äººçœ¼å‰ä¸€äº®ã€åˆåœ¨æƒ…ç†ä¹‹ä¸­çš„åç»­ä¸¤è¡Œå‰§æƒ…ã€‚\n\n"
            user_content += "ç›´æ¥è¾“å‡ºä¸¤è¡Œæ–‡æœ¬ï¼Œä¸è¦ä»»ä½•å…¶ä»–å†…å®¹ï¼š"
            
            # 7. è°ƒç”¨AIç”Ÿæˆé¢„æµ‹
            payload = {
                "model": self._model,
                "messages": [
                    {
                        "role": "system",
                        "content": system_content,
                    },
                    {
                        "role": "user",
                        "content": user_content
                    },
                ],
                "temperature": 0.8,  # ä½¿ç”¨è¾ƒé«˜æ¸©åº¦ä»¥å¢åŠ åˆ›é€ æ€§å’Œæ„å¤–æ€§
                "stream": False,
            }
            
            try:
                response = self._session.post(
                    self._base_url,
                    headers=self._build_headers(),
                    json=payload,
                    timeout=self._timeout_seconds,
                )
            except requests.RequestException as exc:
                raise AIError("ç½‘ç»œå¼‚å¸¸ï¼Œæ— æ³•è¿æ¥è‡³ AI æœåŠ¡ã€‚") from exc
            
            if response.status_code >= 500:
                raise AIError("AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")
            
            if response.status_code == 401:
                raise AIError("AI API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚")
            
            if not response.ok:
                raise AIError(f"å‰§æƒ…é¢„æµ‹å¤±è´¥ï¼š{response.status_code} {response.text}")
            
            try:
                data: Dict[str, Any] = response.json()
            except ValueError as exc:
                raise AIError("æ— æ³•è§£æ AI å“åº”ï¼Œè¯·ç¨åå†è¯•ã€‚") from exc
            
            # æ‰“å°Tokenä½¿ç”¨ç»Ÿè®¡ï¼ˆçŸ¥è¯†åº“å¢å¼ºå‰§æƒ…é¢„æµ‹ï¼‰
            if "usage" in data:
                self._print_token_usage(data["usage"], operation="çŸ¥è¯†åº“å¢å¼ºå‰§æƒ…é¢„æµ‹")
            
            choices = data.get("choices")
            if not choices:
                raise AIError("AI æœªè¿”å›å†…å®¹ï¼Œè¯·ç¨åå†è¯•ã€‚")
            
            message = choices[0].get("message", {})
            content = message.get("content")
            if not content:
                raise AIError("AI å“åº”å†…å®¹ä¸ºç©ºã€‚")
            
            return content.strip()
            
        except Exception as e:
            # å¦‚æœçŸ¥è¯†åº“æ£€ç´¢æˆ–é¢„æµ‹å¤±è´¥ï¼Œå›é€€åˆ°æ™®é€šé¢„æµ‹
            print(f"[ERROR] çŸ¥è¯†åº“å¢å¼ºé¢„æµ‹å¤±è´¥: {str(e)}ï¼Œå›é€€åˆ°æ™®é€šé¢„æµ‹")
            import traceback
            traceback.print_exc()
            return self.predict_plot_continuation(current_context, style_prompt)
    
    def batch_polish_document(self, content: str, requirement: str = "") -> str:
        """æ‰¹é‡æ¶¦è‰²æ•´ä¸ªæ–‡æ¡£
        
        Args:
            content: è¦æ¶¦è‰²çš„å®Œæ•´æ–‡æ¡£å†…å®¹
            requirement: ç”¨æˆ·çš„æ¶¦è‰²éœ€æ±‚ï¼ˆä¾‹å¦‚ï¼šæå‡ä¸“ä¸šæ€§ã€å£è¯­åŒ–ç­‰ï¼‰
        
        Returns:
            æ¶¦è‰²åçš„æ–‡æ¡£å†…å®¹
        """
        # æ„å»ºç³»ç»Ÿæç¤ºè¯
        system_content = "ä½ æ˜¯ä¸€ä½èµ„æ·±ä¸­æ–‡æ–‡æ¡£ç¼–è¾‘å’Œæ¶¦è‰²ä¸“å®¶ã€‚"
        
        # å¦‚æœæœ‰ç”¨æˆ·éœ€æ±‚ï¼ŒåŠ å…¥éœ€æ±‚è¯´æ˜
        if requirement:
            system_content += f"\n\nã€æ¶¦è‰²éœ€æ±‚ã€‘\n{requirement}"
        
        # æ·»åŠ æ ¸å¿ƒä»»åŠ¡æŒ‡ä»¤
        system_content += (
            "\n\nã€ä»»åŠ¡ã€‘"
            "\nè¯·å¯¹ç”¨æˆ·æä¾›çš„æ–‡æ¡£å†…å®¹è¿›è¡Œå…¨é¢æ¶¦è‰²å’Œä¼˜åŒ–ï¼š"
            "\n1. ä¿æŒåŸæ–‡çš„æ ¸å¿ƒæ„æ€å’Œç»“æ„ä¸å˜"
            "\n2. ä¼˜åŒ–è¯­å¥è¡¨è¾¾ï¼Œæå‡æµç•…åº¦å’Œå¯è¯»æ€§"
            "\n3. ä¿®æ­£è¯­æ³•é”™è¯¯å’Œä¸å½“ç”¨è¯"
            "\n4. æ ¹æ®ç”¨æˆ·éœ€æ±‚è°ƒæ•´æ–‡æœ¬é£æ ¼"
            "\n5. ä¿æŒæ®µè½æ ¼å¼å’Œæ¢è¡Œç»“æ„"
            "\n\nã€è¾“å‡ºè¦æ±‚ã€‘"
            "\n- ç›´æ¥è¾“å‡ºæ¶¦è‰²åçš„å®Œæ•´æ–‡æ¡£å†…å®¹"
            "\n- ä¸è¦æ·»åŠ ä»»ä½•è§£é‡Šã€è¯„è®ºæˆ–é¢å¤–è¯´æ˜"
            "\n- ä¿æŒåŸæ–‡çš„æ®µè½ç»“æ„å’Œæ¢è¡Œ"
            "\n- åªè¾“å‡ºæ¶¦è‰²åçš„æ–‡æœ¬"
        )
        
        payload = {
            "model": self._model,
            "messages": [
                {
                    "role": "system",
                    "content": system_content
                },
                {
                    "role": "user",
                    "content": content
                }
            ],
            "temperature": self._temperature,
            "stream": False
        }
        
        try:
            # æ‰¹é‡æ¶¦è‰²ä½¿ç”¨æ›´é•¿è¶…æ—¶
            response = self._session.post(
                self._base_url,
                headers=self._build_headers(),
                json=payload,
                timeout=self._timeout_seconds * 2,
            )
            
        except requests.Timeout as exc:
            raise AIError("è¯·æ±‚è¶…æ—¶ï¼Œæ–‡æ¡£è¾ƒé•¿å¯èƒ½éœ€è¦æ›´é•¿æ—¶é—´ï¼Œè¯·ç¨åé‡è¯•ã€‚") from exc
        except requests.ConnectionError as exc:
            raise AIError("æ— æ³•è¿æ¥è‡³ AI æœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œã€‚") from exc
        except requests.RequestException as exc:
            raise AIError(f"ç½‘ç»œå¼‚å¸¸ï¼š{str(exc)}") from exc
        
        if response.status_code >= 500:
            raise AIError("AI æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚")
        
        if response.status_code == 401:
            raise AIError("AI API è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®ã€‚")
        
        if not response.ok:
            raise AIError(f"æ‰¹é‡æ¶¦è‰²å¤±è´¥ï¼š{response.status_code} {response.text}")
        
        try:
            data: Dict[str, Any] = response.json()
        except ValueError as exc:
            raise AIError("æ— æ³•è§£æ AI å“åº”ï¼Œè¯·ç¨åå†è¯•ã€‚") from exc
        
        # æ‰“å°Tokenä½¿ç”¨ç»Ÿè®¡
        if "usage" in data:
            self._print_token_usage(data["usage"], operation="æ‰¹é‡æ¶¦è‰²")
        
        choices = data.get("choices")
        if not choices:
            raise AIError("AI æœªè¿”å›å†…å®¹ï¼Œè¯·ç¨åå†è¯•ã€‚")
        
        message = choices[0].get("message", {})
        content = message.get("content")
        
        if not content:
            raise AIError("AI å“åº”å†…å®¹ä¸ºç©ºã€‚")
        
        print(f"[DEBUG API] batch_polish_document å®Œæˆï¼Œè¿”å›å†…å®¹é•¿åº¦: {len(content)}", flush=True)
        
        return content.strip()
    
    def check_connection_alive(self) -> bool:
        """è½»é‡çº§è¿æ¥æ£€æŸ¥"""
        return hasattr(self, '_session') and self._session is not None
    
    def test_connection(self) -> Dict[str, Any]:
        """æµ‹è¯•APIè¿æ¥"""
        try:
            test_payload = {
                "model": self._model,
                "messages": [{"role": "user", "content": "test"}],
                "temperature": 0.1,
                "max_tokens": 5,
                "stream": False,
            }
            
            response = self._session.post(
                self._base_url,
                headers=self._build_headers(),
                json=test_payload,
                timeout=10,
            )
            
            return {
                "success": response.status_code == 200,
                "message": "è¿æ¥æ­£å¸¸" if response.status_code == 200 else f"é”™è¯¯: {response.status_code}",
                "status_code": response.status_code
            }
        except Exception as e:
            return {
                "success": False,
                "message": str(e),
                "status_code": None
            }
    
    def warmup_connection(self) -> Dict[str, Any]:
        """è½»é‡çº§é¢„çƒ­ - Sessionè‡ªåŠ¨ç®¡ç†è¿æ¥ï¼Œæ— éœ€é¢å¤–æ“ä½œ"""
        return {
            "success": True,
            "message": "å°±ç»ª",
            "warmup_time": 0.0
        }
    
    def is_warmed_up(self) -> bool:
        """æ£€æŸ¥è¿æ¥æ˜¯å¦å·²é¢„çƒ­"""
        return True  # Sessionå§‹ç»ˆå°±ç»ª
    
    def close(self):
        """å…³é—­è¿æ¥æ± ï¼Œé‡Šæ”¾èµ„æº"""
        try:
            if hasattr(self, '_session') and self._session:
                self._session.close()
        except Exception:
            pass  # å¿½ç•¥å…³é—­æ—¶çš„é”™è¯¯
    
    def __del__(self):
        """ææ„å‡½æ•° - ç¡®ä¿èµ„æºè¢«é‡Šæ”¾"""
        self.close()
